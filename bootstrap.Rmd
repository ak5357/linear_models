---
title: "Bootstrap"
author: "ak5357"
date: "2024-11-14"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(modelr)
library(p8105.datasets)

set.seed(1)
```

Do some bootstrapping!

Make up some data.

```{r}
n_samp = 250

sim_df_constant =
  tibble(
    x = rnorm(n_samp, 1, 1),
    error = rnorm(n_samp, 0, 1),
    y = 2 + 3 * x + error
  )

sim_df_nonconstant =
  sim_df_constant |> 
  mutate(
    error = error * .75 * x,
    y = 2 + 3 * x + error
  )
```


Let's look at these.

```{r}
sim_df_constant |> 
  ggplot(aes(x = x, y = y)) +
  geom_point() +
  stat_smooth(method = "lm")

sim_df_nonconstant |> 
  ggplot(aes(x = x, y = y)) +
  geom_point() +
  stat_smooth(method = "lm")
```

Look at regression results. Moral of the story: Can't always trust p-values.

```{r}
sim_df_constant |> 
  lm(y ~ x, data = _) |> 
  broom::tidy() |> 
  knitr::kable(digits = 3)

sim_df_nonconstant |> 
  lm(y ~ x, data = _) |> 
  broom::tidy() |> 
  knitr::kable(digits = 3)
```

## Draw a bootstrap sample.

* replace = TRUE means that points can be re-selected in the bootstrap sample.

```{r}
boot_sample = function(df){
  boot_df = 
    sample_frac(df, replace = TRUE) |> 
    arrange(x)
  
  return(boot_df)
}
```

Let's try running this!

```{r}
sim_df_nonconstant |>
  boot_sample() |> 
  ggplot(aes(x = x, y = y)) +
  geom_point(alpha = 0.5) +
  stat_smooth(method = "lm")
```


Can we do this as part of an anlysis?

```{r}
sim_df_nonconstant |> 
  boot_sample() |> 
  lm(y ~ x, data = _) |> 
  broom::tidy() |> 
  knitr::kable(digits = 3)
```

## Bootstrap A LOT

We see that the final estimates, after using 1000 samples, have more certainty in the intercept and less certainty in the slope--which reflects the fact that there's more variation farther away from x = 0. This is how the bootstrap simulation works in our benefit.

```{r}
boot_straps =
  tibble(
    strap_number = 1:1000
  ) |> 
  mutate(
    strap_sample = map(strap_number, \(i) boot_sample(df = sim_df_nonconstant)),
    models = map(strap_sample, \(df) lm(y ~ x, data = df)),
    results = map(models, broom::tidy)
  )

bootstrap_results = 
  boot_straps |> 
  select(strap_number, results) |> 
  unnest(results) |> 
  group_by(term) |> 
  summarize(
    boot_se = sd(estimate)
  ) |> 
  knitr::kable(digits = 3)

bootstrap_results
```


## 

```{r}
boot_straps = 
  sim_df_nonconstant |> 
  modelr::bootstrap(1000) |> 
  mutate(
    strap = map(strap, as_tibble),
    models = map(strap, \(df) lm(y ~ x, data = df)),
    results = map(models, broom::tidy)
  ) |> 
  select(.id, results) |> 
  unnest(results)

boot_straps
```

## What do you want to report

```{r}
boot_straps |> 
  group_by(term) |> 
  summarize(
    boot_est = mean(estimate),
    boot_se = sd(estimate),
    boot_ci_ll = quantile(estimate, .025),
    boot_ci_ul = quantile(estimate, .975)
  )
```


## Air BNB

```{r}
data("nyc_airbnb")

manhattan_df = 
  nyc_airbnb |> 
  mutate(stars = review_scores_location / 2) |> 
  rename(borough = neighbourhood_group, neighborhood = neighbourhood) |> 
  filter(borough == "Manhattan") |> 
  select(price, stars, room_type) |> 
  drop_na()
```

Plot the data.

```{r}
manhattan_df |> 
  ggplot(aes(x = stars, y = price)) +
  geom_point() +
  stat_smooth(method = "lm", se = FALSE)
```

Fit a regression.

```{r}
manhattan_df |> 
  lm(price ~ stars + room_type, data = _) |> 
  broom::tidy() |> 
  knitr::kable(digits = 3)
```

Bootstrap for a better inference.

```{r}
boot_results = manhattan_df |> 
  modelr::bootstrap(1000) |> 
  mutate(
    strap = map(strap, as_tibble),
    models = map(strap, \(df) lm(price ~ stars + room_type, data = df)),
    results = map(models, broom::tidy)
  ) |> 
  select(.id, results) |> 
  unnest(results)

boot_results |> 
  filter(term == "stars") |> 
  ggplot(aes(x = estimate)) +
  geom_density()


boot_results |> 
  group_by(term) |> 
  summarize(
    boot_est = mean(estimate),
    boot_se = sd(estimate),
    boot_ci_ll = quantile(estimate, .025),
    boot_ci_ul = quantile(estimate, .975)
  )

```








